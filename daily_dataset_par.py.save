import time
import multiprocessing as mp
from datetime import datetime, timedelta
import pandas as pd
import ndvi_23072018
import temperature_daily_numpy
import precipitation_daily_numpy
import wind_daily_numpy
import lst_8day_numpy
import dewpoint_temperature_daily_numpy
import geopandas as gpd
from functools import reduce
import datetime
import os
import pygrib
import sys

def daterange(date1, date2):
    for n in range(int((date2 - date1).days)+1):
        yield date1 + timedelta(n)

def parallel_process(date,dataset_join,temps,dew_temps,wind,precs):
    abs_time = time.time()
    #dataset_join = gpd.read_file('/home/sg/Projects/FIrehub-model/dataset_greece_static/greece_lc_dem_withtiles/greece_withtiles.shp')
    print(mp.cpu_count())

    start_time = time.time()

    #ndvi = ndvi_23072018.run_ndvi(date)
    procdict={}
    #q=mp.Queue()
    #q2=mp.Queue()
    queues = [mp.Queue(), mp.Queue(), mp.Queue(), mp.Queue(), mp.Queue(), mp.Queue()]
    #queues = [mp.Queue(), mp.Queue()]
    #p =  mp.Process(target=testpar, args=(14,q,))
    #p2 =  mp.Process(target=testpar, args=(20,q2,))
    #procdict['p'] = {'proc':p, 'start':datetime.now(), 'status':'running', 'queue':q}
    #procdict['p2'] = {'proc':p2, 'start':datetime.now(), 'status':'running', 'queue':q2}

    procdict['ndvi_process'] = {'proc':mp.Process(target=ndvi_23072018.run_ndvi, args=[dataset_join,date,queues[0]]), 'start':datetime.datetime.now(), 'status':'running', 'queue':queues[0]}
    procdict['temp_process'] = {'proc':mp.Process(target=temperature_daily_numpy.run_temp, args=[dataset_join,date,temps,queues[1]]), 'start':datetime.datetime.now(), 'status':'running', 'queue':queues[1]}
    procdict['rain_process'] = {'proc':mp.Process(target=precipitation_daily_numpy.run_prec, args=[dataset_join,date,precs,queues[2]]), 'start':datetime.datetime.now(),'status':'running', 'queue':queues[2]}
    procdict['wind_process'] = {'proc':mp.Process(target=wind_daily_numpy.run_wind, args=[dataset_join, date,wind,queues[3]]), 'start':datetime.datetime.now(),'status':'running', 'queue':queues[3]}
    procdict['lst_process'] = {'proc':mp.Process(target=lst_8day_numpy.run_lst, args=[dataset_join, date,queues[4]]), 'start':datetime.datetime.now(),'status':'running', 'queue':queues[4]}
    procdict['dew_temp_process'] = {'proc':mp.Process(target=dewpoint_temperature_daily_numpy.run_dew_temp, args=[dataset_join, date,dew_temps,queues[5]]), 'start':datetime.datetime.now(),'status':'running', 'queue':queues[5]}

    for p in procdict:
        procdict[p]['proc'].start()
        time.sleep(3)

    #procdict['ndviprocess']['proc'].start()

    #print('NDVI DONE in %s minutes' % ((time.time() - start_time)/60))

    print('Running processes...')
    dfdict = {}
    while True:
        for proc in procdict:
            try:
                while not procdict[proc]['queue'].empty():
                    dfdict[proc]=procdict[proc]['queue'].get_nowait()
                    print(proc)
                   #print(dfdict[proc])
            except:
                i=1
        for proc in procdict:
            if not procdict[proc]['proc'].is_alive() and procdict[proc]['status']=='running':
                print('Process %s finished in %s'%(proc,datetime.datetime.now()-procdict[proc]['start']))
                procdict[proc]['status']='finished'
                break
        '''
        if not procdict[proc]['proc'].is_alive():
            del procdict[proc]
        '''
        if all(not procdict[x]['proc'].is_alive() for x in procdict):
            dfs = [dfdict['ndvi_process'],dfdict['temp_process'],dfdict['rain_process'],dfdict['wind_process'],dfdict['lst_process'],dfdict['dew_temp_process']]
            #dfs = [dfdict['ndvi_process'], dfdict['temp_process'], dfdict['rain_process'], dfdict['wind_process']]
            df_final = reduce(lambda left, right: pd.merge(left, right, on='id'), dfs)
            #df_final.to_csv('/home/sg/Projects/FIrehub-model/tests_2019/June_2019/'+ date+'.csv')
            st_dir = '/users/pa21/sgirtsou/production'
            if not os.path.exists(os.path.join(st_dir,date[0:4],date[4:6])):
                os.makedirs(os.path.join(st_dir,date[0:4],date[4:6]))
            df_final.to_csv(os.path.join(st_dir,date[0:4],date[4:6], date +'.csv'))
            print("Script finished in %s minutes" %((time.time() - abs_time)/60))
            break
        time.sleep(1)


dates = []
#start = '20100701'
#end = '20100701'
start = str(sys.argv[1])
end = str(sys.argv[2])
dataset_join = gpd.read_file('/users/pa21/sgirtsou/transfered_files/data/vector/greece_withtiles.shp')
dataset_join['x'] = dataset_join.geometry.x
dataset_join['y'] = dataset_join.geometry.y
temps = pygrib.open("")
print("Temps ...... ok")
dew_temps = pygrib.open("/users/pa21/sgirtsou/transfered_files/data/gribs/dewpoint_temp.grib")
print("Dew Temps ...... ok")
wind = pygrib.open("/users/pa21/sgirtsou/transfered_files/data/gribs/era5-land-wind-2010-2020.grb")
print("Wind ...... ok")
precs = pygrib.open("/users/pa21/sgirtsou/transfered_files/data/gribs/downloadTotalPrecipitation2010_2019.grib")
print("precs ...... ok")
start_date = datetime.datetime.strptime(start, "%Y%m%d")
end_date = datetime.datetime.strptime(end, "%Y%m%d")

for dt in daterange(start_date, end_date):
    dates.append(dt.strftime("%Y%m%d"))

for date in dates:
    print(date)
    parallel_process(date,dataset_join,temps,dew_temps,wind,precs)
